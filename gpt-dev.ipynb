{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efbedf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2026-01-17 09:27:24--  https://huggingface.co/datasets/aaru2330/Mahabharath/resolve/main/Mahabharata.txt\n",
      "Resolving huggingface.co (huggingface.co)... 13.225.5.26, 13.225.5.100, 13.225.5.95, ...\n",
      "Connecting to huggingface.co (huggingface.co)|13.225.5.26|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://cas-bridge.xethub.hf.co/xet-bridge-us/6612ca8cdb728ea967e5b1d8/2b7db1d108c8a112055a34e8fa2a3685eff97a7e1c604df2b75c4fdec8037e8b?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20260117%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20260117T092725Z&X-Amz-Expires=3600&X-Amz-Signature=89ced61805b929cfe8765d566e4e3964052b694de5bd9f655baa9dc87274db86&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27Mahabharata.txt%3B+filename%3D%22Mahabharata.txt%22%3B&response-content-type=text%2Fplain&x-id=GetObject&Expires=1768645645&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc2ODY0NTY0NX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82NjEyY2E4Y2RiNzI4ZWE5NjdlNWIxZDgvMmI3ZGIxZDEwOGM4YTExMjA1NWEzNGU4ZmEyYTM2ODVlZmY5N2E3ZTFjNjA0ZGYyYjc1YzRmZGVjODAzN2U4YioifV19&Signature=OfqPgx9SC35azk8m4I1tWFhQxJM-TS-J9BqJSug2rV2edknlw5tT49jIRsh25btTIDqE1-4JA2NbYnmzjmTbBmgd7xDcg6Z99TDcMkPtPFZbqXnOOUOOTNQSDF25Z4EtPYuXc0pBXqL4g%7EfCD6Fi3mU8eaAdZ3M4%7E87tebyoL3ccjDVGJxQ%7EhNYX1bDrl9pg3STpz17wa7Y-khNc5Rb-rM35VAZg9tpQAgfs3pAQBwiR0I8THUok2EqT-6gvrZSR9A1MIToQqooYDiaaSDRtU6SEsrqLCXVq0kxUo4oxsF4dm6Rszolx%7EfaT1K0A3DPbj7E5AtwxYrIa%7EpN76woPiQ__&Key-Pair-Id=K2L8F4GPSG1IFC [following]\n",
      "--2026-01-17 09:27:25--  https://cas-bridge.xethub.hf.co/xet-bridge-us/6612ca8cdb728ea967e5b1d8/2b7db1d108c8a112055a34e8fa2a3685eff97a7e1c604df2b75c4fdec8037e8b?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20260117%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20260117T092725Z&X-Amz-Expires=3600&X-Amz-Signature=89ced61805b929cfe8765d566e4e3964052b694de5bd9f655baa9dc87274db86&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27Mahabharata.txt%3B+filename%3D%22Mahabharata.txt%22%3B&response-content-type=text%2Fplain&x-id=GetObject&Expires=1768645645&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc2ODY0NTY0NX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82NjEyY2E4Y2RiNzI4ZWE5NjdlNWIxZDgvMmI3ZGIxZDEwOGM4YTExMjA1NWEzNGU4ZmEyYTM2ODVlZmY5N2E3ZTFjNjA0ZGYyYjc1YzRmZGVjODAzN2U4YioifV19&Signature=OfqPgx9SC35azk8m4I1tWFhQxJM-TS-J9BqJSug2rV2edknlw5tT49jIRsh25btTIDqE1-4JA2NbYnmzjmTbBmgd7xDcg6Z99TDcMkPtPFZbqXnOOUOOTNQSDF25Z4EtPYuXc0pBXqL4g%7EfCD6Fi3mU8eaAdZ3M4%7E87tebyoL3ccjDVGJxQ%7EhNYX1bDrl9pg3STpz17wa7Y-khNc5Rb-rM35VAZg9tpQAgfs3pAQBwiR0I8THUok2EqT-6gvrZSR9A1MIToQqooYDiaaSDRtU6SEsrqLCXVq0kxUo4oxsF4dm6Rszolx%7EfaT1K0A3DPbj7E5AtwxYrIa%7EpN76woPiQ__&Key-Pair-Id=K2L8F4GPSG1IFC\n",
      "Resolving cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)... 13.227.249.11, 13.227.249.95, 13.227.249.7, ...\n",
      "Connecting to cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)|13.227.249.11|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 14921157 (14M) [text/plain]\n",
      "Saving to: ‘Mahabharata.txt.1’\n",
      "\n",
      "Mahabharata.txt.1   100%[===================>]  14.23M  --.-KB/s    in 0.1s    \n",
      "\n",
      "2026-01-17 09:27:25 (130 MB/s) - ‘Mahabharata.txt.1’ saved [14921157/14921157]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download the text\n",
    "!wget -nc https://huggingface.co/datasets/aaru2330/Mahabharath/resolve/main/Mahabharata.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f925e5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the text file\n",
    "with open('Mahabharata.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46bf9195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of dataset in characters: 14921047\n"
     ]
    }
   ],
   "source": [
    "print(f\"The length of dataset in characters: {len(text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "caedbd13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Complete Mahabharata in English\n",
      "The Mahabharata\n",
      "of\n",
      "Krishna-Dwaipayana Vyasa\n",
      "\n",
      "BOOK 1\n",
      "ADI PARVA\n",
      "Translated into English Prose from the Original Sanskrit Text by Kisari Mohan Ganguli [1883-1896]\n",
      "Scanned at sacred-texts.com, 2003. Proofed at Distributed Proofing, Juliet Sutherland, Project Manager. Additional proofing\n",
      "and formatting at sacred-texts.com, by J. B. Hare.\n",
      "TRANSLATOR'S PREFACE\n",
      "The object of a translator should ever be to hold the mirror upto his author. That being so, his chief duty is to represent so far as\n",
      "practicable the manner in which his author's ideas have been expressed, retaining if possible at the sacrifice of idiom and taste\n",
      "all the peculiarities of his author's imagery and of language as well. In regard to translations from the Sanskrit, nothing is easier\n",
      "than to dish up Hindu ideas, so as to make them agreeable to English taste. But the endeavour of the present translator has been\n",
      "to give in the following pages as literal a rendering as possible of the great wo\n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25dfea7b",
   "metadata": {},
   "source": [
    "# Tokenzing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddac8610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\f !\"#&'(),-.0123456789:;?ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]_`abcdefghijklmnopqrstuvwxyz—\n",
      "84\n"
     ]
    }
   ],
   "source": [
    "# Let observe the vocabulary\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92545d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[64, 65, 2, 57, 74, 66, 77, 70]\n",
      "hi arjun\n"
     ]
    }
   ],
   "source": [
    "# Mapping characters into integers for encoding/decoding\n",
    "# character level tokenizers\n",
    "stoi = { ch:i for i,ch in enumerate(chars)}\n",
    "itos = { i:ch for i,ch in enumerate(chars)}\n",
    "encode = lambda s: [stoi[c] for c in s] # encode: string --> list of integers\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # decode: list of integers --> string\n",
    "\n",
    "print(encode(\"hi arjun\"))\n",
    "print(decode(encode(\"hi arjun\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da11c7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cea3d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/MiniGPT/.venv/lib/python3.12/site-packages/torch/_subclasses/functional_tensor.py:279: UserWarning: Failed to initialize NumPy: No module named 'numpy' (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([14921047]) <built-in method type of Tensor object at 0x7d9283216440>\n",
      "tensor([74, 67,  2,  ...,  0,  0,  1])\n"
     ]
    }
   ],
   "source": [
    "# Encoding the entire text using pytorch\n",
    "import torch\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.type)\n",
    "print(data[1000:]) # GPT view of the 1000 chars "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fba26aa",
   "metadata": {},
   "source": [
    "# Training the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "589dfa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the train/validation sets\n",
    "n = int(0.8*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae9682c",
   "metadata": {},
   "source": [
    "Block Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "262cc2dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([45, 64, 61,  2, 28, 71, 69, 72, 68])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the training example length sent to the model \n",
    "block_size = 8\n",
    "train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38d6642",
   "metadata": {},
   "source": [
    "In this single block of 9 characters, we have 8 individual examples packed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7645b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when the input is tensor([45]), the target is: 64\n",
      "when the input is tensor([45, 64]), the target is: 61\n",
      "when the input is tensor([45, 64, 61]), the target is: 2\n",
      "when the input is tensor([45, 64, 61,  2]), the target is: 28\n",
      "when the input is tensor([45, 64, 61,  2, 28]), the target is: 71\n",
      "when the input is tensor([45, 64, 61,  2, 28, 71]), the target is: 69\n",
      "when the input is tensor([45, 64, 61,  2, 28, 71, 69]), the target is: 72\n",
      "when the input is tensor([45, 64, 61,  2, 28, 71, 69, 72]), the target is: 68\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"when the input is {context}, the target is: {target}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e765514",
   "metadata": {},
   "source": [
    "Batch Sizes for GPU optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5af56ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[65, 70, 60, 77, 68, 63, 61,  2],\n",
      "        [ 2, 77, 70, 76, 71,  2, 64, 65],\n",
      "        [79, 57, 74, 74, 65, 71, 74, 75],\n",
      "        [61, 60, 12,  2, 45, 64, 61,  2]])\n",
      "Targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[70, 60, 77, 68, 63, 61,  2, 65],\n",
      "        [77, 70, 76, 71,  2, 64, 65, 69],\n",
      "        [57, 74, 74, 65, 71, 74, 75,  2],\n",
      "        [60, 12,  2, 45, 64, 61,  2, 69]])\n",
      "----------\n",
      "When the input is: [65], the target is: 70\n",
      "When the input is: [65, 70], the target is: 60\n",
      "When the input is: [65, 70, 60], the target is: 77\n",
      "When the input is: [65, 70, 60, 77], the target is: 68\n",
      "When the input is: [65, 70, 60, 77, 68], the target is: 63\n",
      "When the input is: [65, 70, 60, 77, 68, 63], the target is: 61\n",
      "When the input is: [65, 70, 60, 77, 68, 63, 61], the target is: 2\n",
      "When the input is: [65, 70, 60, 77, 68, 63, 61, 2], the target is: 65\n",
      "When the input is: [2], the target is: 77\n",
      "When the input is: [2, 77], the target is: 70\n",
      "When the input is: [2, 77, 70], the target is: 76\n",
      "When the input is: [2, 77, 70, 76], the target is: 71\n",
      "When the input is: [2, 77, 70, 76, 71], the target is: 2\n",
      "When the input is: [2, 77, 70, 76, 71, 2], the target is: 64\n",
      "When the input is: [2, 77, 70, 76, 71, 2, 64], the target is: 65\n",
      "When the input is: [2, 77, 70, 76, 71, 2, 64, 65], the target is: 69\n",
      "When the input is: [79], the target is: 57\n",
      "When the input is: [79, 57], the target is: 74\n",
      "When the input is: [79, 57, 74], the target is: 74\n",
      "When the input is: [79, 57, 74, 74], the target is: 65\n",
      "When the input is: [79, 57, 74, 74, 65], the target is: 71\n",
      "When the input is: [79, 57, 74, 74, 65, 71], the target is: 74\n",
      "When the input is: [79, 57, 74, 74, 65, 71, 74], the target is: 75\n",
      "When the input is: [79, 57, 74, 74, 65, 71, 74, 75], the target is: 2\n",
      "When the input is: [61], the target is: 60\n",
      "When the input is: [61, 60], the target is: 12\n",
      "When the input is: [61, 60, 12], the target is: 2\n",
      "When the input is: [61, 60, 12, 2], the target is: 45\n",
      "When the input is: [61, 60, 12, 2, 45], the target is: 64\n",
      "When the input is: [61, 60, 12, 2, 45, 64], the target is: 61\n",
      "When the input is: [61, 60, 12, 2, 45, 64, 61], the target is: 2\n",
      "When the input is: [61, 60, 12, 2, 45, 64, 61, 2], the target is: 69\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(2026)\n",
    "batch_size = 4 # independent sequences processed parallely\n",
    "block_size = 8 # Maximum context length of predicitons\n",
    "\n",
    "def get_batch(split):\n",
    "    # generates a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size, ))\n",
    "    x = torch.stack([data[i: i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1: i+block_size+1] for i in ix])\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print(\"Inputs:\")\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print(\"Targets:\")\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print('----------')\n",
    "\n",
    "for b in range(batch_size): # batch dimension\n",
    "    for t in range(block_size): # time dimension\n",
    "        context = xb[b, : t+1]\n",
    "        target = yb[b, t]\n",
    "        print(f\"When the input is: {context.tolist()}, the target is: {target}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba9e56c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[65, 70, 60, 77, 68, 63, 61,  2],\n",
      "        [ 2, 77, 70, 76, 71,  2, 64, 65],\n",
      "        [79, 57, 74, 74, 65, 71, 74, 75],\n",
      "        [61, 60, 12,  2, 45, 64, 61,  2]])\n"
     ]
    }
   ],
   "source": [
    "print(xb) # Input to the transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462a0deb",
   "metadata": {},
   "source": [
    "# Let us start training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607676cb",
   "metadata": {},
   "source": [
    "###  Defining the neural model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a83bb815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 84])\n",
      "tensor(4.8717, grad_fn=<NllLossBackward0>)\n",
      "\n",
      "\n",
      "m`D,h9.i_Tdxa5aC3Bk0eE]\f3eamQIFrSqZQq`]qtUqSgEokos!CnT0Mom`#,e?zYV#KpL`fF(OFclN-Z\"59`4Z\\GX,,qs,ds]\f\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class BiGramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        # Each token directly reads off the logits of the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "    \n",
    "    def forward(self, idx, targets=None):\n",
    "\n",
    "        # idx and targets are both (B, T) tensor of integers\n",
    "        # Basically we are passing the input idx to get the logits for next token prediction\n",
    "        logits = self.token_embedding_table(idx) # (B, T, C) = (batch_size, time = block_size, channel = vocab_size)\n",
    "\n",
    "        if targets is None: # If no targets provided, we are in generation mode\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            # Reshape the logits and targets to calculate the loss as CrossEntropyLoss expects (N, C) and (N,) shape respectively\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # get the predictions\n",
    "            logits, _ = self(idx)\n",
    "            \n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # (B, C) # last element in time dimension\n",
    "\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1) # single prediciton in each batch\n",
    "\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        \n",
    "        return idx\n",
    "\n",
    "m = BiGramLanguageModel(vocab_size)\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "\n",
    "idx = torch.zeros((1, 1), dtype=torch.long)\n",
    "print(decode(m.generate(idx, max_new_tokens=100)[0].tolist())) # [0] to get the first batch element"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f814e3f2",
   "metadata": {},
   "source": [
    "### Create optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ff5b048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pytorch optimizer and train the model\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c36ae05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 0: 4.889804840087891\n",
      "Loss at step 100: 4.768571376800537\n",
      "Loss at step 200: 4.544029712677002\n",
      "Loss at step 300: 4.630743503570557\n",
      "Loss at step 400: 4.4741291999816895\n",
      "Loss at step 500: 4.363897323608398\n",
      "Loss at step 600: 4.08666467666626\n",
      "Loss at step 700: 4.199620246887207\n",
      "Loss at step 800: 4.088075160980225\n",
      "Loss at step 900: 3.969822883605957\n",
      "Loss at step 1000: 3.8658130168914795\n",
      "Loss at step 1100: 3.739835739135742\n",
      "Loss at step 1200: 3.787188768386841\n",
      "Loss at step 1300: 3.713005542755127\n",
      "Loss at step 1400: 3.5578134059906006\n",
      "Loss at step 1500: 3.575252056121826\n",
      "Loss at step 1600: 3.3790228366851807\n",
      "Loss at step 1700: 3.343362331390381\n",
      "Loss at step 1800: 3.278594732284546\n",
      "Loss at step 1900: 3.2958972454071045\n",
      "Loss at step 2000: 3.1285407543182373\n",
      "Loss at step 2100: 3.205326795578003\n",
      "Loss at step 2200: 3.0065724849700928\n",
      "Loss at step 2300: 2.8971316814422607\n",
      "Loss at step 2400: 2.964149236679077\n",
      "Loss at step 2500: 3.0089097023010254\n",
      "Loss at step 2600: 2.9624223709106445\n",
      "Loss at step 2700: 2.960226058959961\n",
      "Loss at step 2800: 2.9600255489349365\n",
      "Loss at step 2900: 2.912883996963501\n",
      "Loss at step 3000: 2.8657565116882324\n",
      "Loss at step 3100: 2.782167673110962\n",
      "Loss at step 3200: 2.6912178993225098\n",
      "Loss at step 3300: 2.7326860427856445\n",
      "Loss at step 3400: 2.6891303062438965\n",
      "Loss at step 3500: 2.661139488220215\n",
      "Loss at step 3600: 2.6962850093841553\n",
      "Loss at step 3700: 2.5988872051239014\n",
      "Loss at step 3800: 2.6847167015075684\n",
      "Loss at step 3900: 2.7576236724853516\n",
      "Loss at step 4000: 2.683713912963867\n",
      "Loss at step 4100: 2.5314531326293945\n",
      "Loss at step 4200: 2.710289478302002\n",
      "Loss at step 4300: 2.6488256454467773\n",
      "Loss at step 4400: 2.571690320968628\n",
      "Loss at step 4500: 2.607184410095215\n",
      "Loss at step 4600: 2.713369846343994\n",
      "Loss at step 4700: 2.615880250930786\n",
      "Loss at step 4800: 2.5982601642608643\n",
      "Loss at step 4900: 2.588960886001587\n",
      "Loss at step 5000: 2.4870002269744873\n",
      "Loss at step 5100: 2.50671648979187\n",
      "Loss at step 5200: 2.704620838165283\n",
      "Loss at step 5300: 2.5822744369506836\n",
      "Loss at step 5400: 2.489675760269165\n",
      "Loss at step 5500: 2.4521849155426025\n",
      "Loss at step 5600: 2.435699224472046\n",
      "Loss at step 5700: 2.5141098499298096\n",
      "Loss at step 5800: 2.543538808822632\n",
      "Loss at step 5900: 2.4665889739990234\n",
      "Loss at step 6000: 2.5520248413085938\n",
      "Loss at step 6100: 2.4382224082946777\n",
      "Loss at step 6200: 2.3774020671844482\n",
      "Loss at step 6300: 2.3374855518341064\n",
      "Loss at step 6400: 2.40999436378479\n",
      "Loss at step 6500: 2.455198049545288\n",
      "Loss at step 6600: 2.489889144897461\n",
      "Loss at step 6700: 2.6481990814208984\n",
      "Loss at step 6800: 2.515016794204712\n",
      "Loss at step 6900: 2.530792713165283\n",
      "Loss at step 7000: 2.404175281524658\n",
      "Loss at step 7100: 2.422469139099121\n",
      "Loss at step 7200: 2.4268882274627686\n",
      "Loss at step 7300: 2.534353017807007\n",
      "Loss at step 7400: 2.4245357513427734\n",
      "Loss at step 7500: 2.4161956310272217\n",
      "Loss at step 7600: 2.485839366912842\n",
      "Loss at step 7700: 2.5019423961639404\n",
      "Loss at step 7800: 2.3862040042877197\n",
      "Loss at step 7900: 2.360438346862793\n",
      "Loss at step 8000: 2.3851940631866455\n",
      "Loss at step 8100: 2.399878978729248\n",
      "Loss at step 8200: 2.4528093338012695\n",
      "Loss at step 8300: 2.331857681274414\n",
      "Loss at step 8400: 2.458395481109619\n",
      "Loss at step 8500: 2.350325345993042\n",
      "Loss at step 8600: 2.45825457572937\n",
      "Loss at step 8700: 2.479076385498047\n",
      "Loss at step 8800: 2.3465232849121094\n",
      "Loss at step 8900: 2.4499354362487793\n",
      "Loss at step 9000: 2.4114227294921875\n",
      "Loss at step 9100: 2.431863784790039\n",
      "Loss at step 9200: 2.3970000743865967\n",
      "Loss at step 9300: 2.382725954055786\n",
      "Loss at step 9400: 2.5841028690338135\n",
      "Loss at step 9500: 2.56941294670105\n",
      "Loss at step 9600: 2.4016847610473633\n",
      "Loss at step 9700: 2.482783079147339\n",
      "Loss at step 9800: 2.488103151321411\n",
      "Loss at step 9900: 2.415131092071533\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for step in range(10000):\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if step % 100 == 0:\n",
    "        print(f\"Loss at step {step}: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22dded16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "surof. stioffys I Drtherot wifof wiomeathrsahangoldglan? tthecovatherf. Rale hatr frbuly Kavas.\"\n",
      "b6.Federnd-wh s witesawhes ble o is, ald ara, a, s, otmarsecucind. f\n",
      "be, NqSEComemice by\n",
      "F\"in oupon fowild by-inge.em wibs l ctrthofrende. Saulisscceenthen s ispestheees tid, whmpred ondf wazlllis Thiots Whilorive, r LVites d kend o!\"\n",
      "ine horel-dhaind t\\543\n",
      "K2EGaelle Aplourse. irto o patof\n",
      "withitond sonin wrn s tr s, tetoleo pr ingn acean by h med pr his o gsshanennd s bonvaifo malgronthean this ty o\n"
     ]
    }
   ],
   "source": [
    "idx = torch.zeros((1, 1), dtype=torch.long)\n",
    "print(decode(m.generate(idx, max_new_tokens=500)[0].tolist())) # ["
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b282b719",
   "metadata": {},
   "source": [
    "# Self-Attention Block\n",
    "The trick is matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5ed43d4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(2026)\n",
    "B, T, C = 4, 8, 2\n",
    "x = torch.randn(B, T, C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e6a5676e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x[b, t] = mean_{i<=t} x[b, i]\n",
    "\n",
    "xbow = torch.zeros((B, T, C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b, :t+1] # (t, C) includes the t-th element\n",
    "        xbow[b, t] = torch.mean(xprev, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c2c9633d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1839,  0.7296],\n",
       "        [ 0.6242,  0.1225],\n",
       "        [-0.0314, -0.7410],\n",
       "        [-1.3574, -0.0220],\n",
       "        [-0.5450,  0.2193],\n",
       "        [-1.4955,  0.3433],\n",
       "        [-0.1916, -0.9030],\n",
       "        [ 0.9982,  0.0361]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a3e6ca20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1839,  0.7296],\n",
       "        [ 0.2201,  0.4261],\n",
       "        [ 0.1363,  0.0370],\n",
       "        [-0.2371,  0.0223],\n",
       "        [-0.2987,  0.0617],\n",
       "        [-0.4982,  0.1086],\n",
       "        [-0.4544, -0.0359],\n",
       "        [-0.2728, -0.0269]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85fd3be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 2\n",
    "wei = torch.tril(torch.ones(T, T))\n",
    "wei = wei / wei.sum(dim=1, keepdim=True)\n",
    "xbow2 = wei @ x # (#B, T, T) @ (B, T, C) --> (B, T, C)\n",
    "torch.allclose(xbow, xbow2) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c25c433",
   "metadata": {},
   "source": [
    " > Note: Even though wei is (T, T) and x is (B, T, C), python will transform (T, T) --> (B, T, T). Batch matrix multiplication was done in a weighted fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758ebdfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.1839,  0.7296],\n",
       "         [ 0.2201,  0.4261],\n",
       "         [ 0.1363,  0.0370],\n",
       "         [-0.2371,  0.0223],\n",
       "         [-0.2987,  0.0617],\n",
       "         [-0.4982,  0.1086],\n",
       "         [-0.4544, -0.0359],\n",
       "         [-0.2728, -0.0269]]),\n",
       " tensor([[-0.1839,  0.7296],\n",
       "         [ 0.2201,  0.4261],\n",
       "         [ 0.1363,  0.0370],\n",
       "         [-0.2371,  0.0223],\n",
       "         [-0.2987,  0.0617],\n",
       "         [-0.4982,  0.1086],\n",
       "         [-0.4544, -0.0359],\n",
       "         [-0.2728, -0.0269]]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow[0], xbow2[0] # Identical batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e801cf5",
   "metadata": {},
   "source": [
    "> Using softmax, we do weighted aggregation of lower triangular matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5f6c748e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 2\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei = torch.zeros((T, T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "xbow3 = wei @ x # (#B, T, T) @ (B, T, C) --> (B, T, C)\n",
    "\n",
    "torch.allclose(xbow, xbow3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "01def175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1839,  0.7296],\n",
       "        [ 0.2201,  0.4261],\n",
       "        [ 0.1363,  0.0370],\n",
       "        [-0.2371,  0.0223],\n",
       "        [-0.2987,  0.0617],\n",
       "        [-0.4982,  0.1086],\n",
       "        [-0.4544, -0.0359],\n",
       "        [-0.2728, -0.0269]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow3[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9b644c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
